{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa3aa23-e2e2-4a6b-94e9-dfb4271bf2b0",
   "metadata": {},
   "source": [
    "Notebook for optimizing the trend analyzer code.\n",
    "To run the notebook, run the command \"jupyter notebook --ip=0.0.0.0 --port=5000 --allow-root --no-browser\". Then open the webpage that opens in replit in a new tab, and enter the token for the server you find from the command \"jupter server list\". If you enter the token in the replit preview it will give you a 403 error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "868f8830-df75-40f4-844e-371030acf6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "from modules import *\n",
    "import os\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dd921eb-5851-448a-9dd4-aa8ece445a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup mlflow\n",
    "mlflow_tracking_uri = \"../../mlflow/experiments\"\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "mlflow.set_experiment(\"TrendFinderOptimizer\")\n",
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23fb65a5-c9f6-453d-9284-fad6223d3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup dspy\n",
    "api_key = os.environ['paul2']\n",
    "lm = dspy.LM('gemini/gemini-2.5-flash', api_key=api_key, max_tokens=8000)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimization-intro",
   "metadata": {},
   "source": [
    "## DSPy Optimization for doc_analyzer\n",
    "\n",
    "Since we don't have labeled training data, we'll use DSPy's signature optimization and prompt engineering techniques to improve the `doc_analyzer` signature performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "setup-optimization",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'datasets' from 'dspy.datasets' (/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/dspy/datasets/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mteleprompt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BootstrapFewShot\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Evaluate\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'datasets' from 'dspy.datasets' (/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/dspy/datasets/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Import optimization modules\n",
    "import dspy\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from dspy.evaluate import Evaluate\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "create-synthetic-examples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 synthetic examples\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic examples for different document types and categories\n",
    "# This helps DSPy understand the expected input/output patterns\n",
    "\n",
    "def create_synthetic_examples():\n",
    "    examples = []\n",
    "    \n",
    "    # Example 1: Realistic inspection report with lengthy content\n",
    "    inspection_report_1 = \"\"\"\n",
    "    INSPECTION REPORT - Document ID: 32037 ALR10C6BZ 097\n",
    "    Date: 07-10-2025\n",
    "    Inspector: AEPACS\n",
    "    Location: Industrial Site NA\n",
    "\n",
    "    SUMMARY OF INSPECTION:\n",
    "    This inspection was conducted in accordance with safety regulations and compliance standards.\n",
    "    The facility was evaluated for adherence to safety protocols, equipment maintenance, and regulatory compliance.\n",
    "\n",
    "    VIOLATIONS IDENTIFIED:\n",
    "    1. Missing safety equipment in Zone A - Safety harnesses not available at designated stations\n",
    "    2. Improper chemical storage in Building 3 - Hazardous materials not properly labeled or contained\n",
    "    3. Emergency exit blocked by equipment in Warehouse B\n",
    "\n",
    "    RECOMMENDATIONS:\n",
    "    - Immediate procurement and installation of safety equipment\n",
    "    - Proper labeling and containment of all hazardous materials\n",
    "    - Clear all emergency exits of obstructions\n",
    "\n",
    "    COMPLIANCE STATUS: Non-compliant - 3 violations found\n",
    "    Next inspection scheduled for 08-15-2025\n",
    "    \"\"\"\n",
    "\n",
    "    examples.append(dspy.Example(\n",
    "        document=inspection_report_1,\n",
    "        categories=[\"document\", \"number of violations\", \"list and details of violations\"],\n",
    "        in_csv=\"\",\n",
    "        last_context=\"Analyzing safety inspection reports for compliance trends\",\n",
    "        next_context=\"Analyzing safety inspection reports for compliance trends. Safety equipment and storage violations are recurring issues.\",\n",
    "        out_csv=\"document,number of violations,list and details of violations\\n32037_ALR10C6BZ_097,3,\\\"Missing safety equipment in Zone A; Improper chemical storage in Building 3; Emergency exit blocked in Warehouse B\\\"\"\n",
    "    ).with_inputs(\"document\", \"categories\", \"in_csv\", \"last_context\"))\n",
    "\n",
    "    # Example 2: Financial document with some missing categories\n",
    "    financial_report = \"\"\"\n",
    "    QUARTERLY FINANCIAL STATEMENT - Q3 2025\n",
    "    Company: TechCorp Industries\n",
    "\n",
    "    REVENUE BREAKDOWN:\n",
    "    Product Sales: $850,000\n",
    "    Service Revenue: $320,000\n",
    "    Total Revenue: $1,170,000\n",
    "\n",
    "    OPERATIONAL EXPENSES:\n",
    "    Salaries and Benefits: $450,000\n",
    "    Equipment and Maintenance: $120,000\n",
    "    Marketing: $85,000\n",
    "    Total Expenses: $655,000\n",
    "\n",
    "    NET PROFIT: $515,000\n",
    "\n",
    "    Note: Employee count data not available in this quarterly report.\n",
    "    Tax information will be provided in annual filing.\n",
    "    \"\"\"\n",
    "\n",
    "    examples.append(dspy.Example(\n",
    "        document=financial_report,\n",
    "        categories=[\"revenue\", \"expenses\", \"profit\", \"employee_count\", \"tax_rate\"],\n",
    "        in_csv=\"\",\n",
    "        last_context=\"Processing quarterly financial reports for trend analysis\",\n",
    "        next_context=\"Processing quarterly financial reports for trend analysis. Revenue trends show consistent growth.\",\n",
    "        out_csv=\"revenue,expenses,profit,employee_count,tax_rate\\n1170000,655000,515000,N/A,N/A\"\n",
    "    ).with_inputs(\"document\", \"categories\", \"in_csv\", \"last_context\"))\n",
    "\n",
    "    # Example 3: Document with no violations (testing N/A handling)\n",
    "    clean_inspection = \"\"\"\n",
    "    INSPECTION REPORT - Document ID: 45892 CLN001\n",
    "    Date: 07-12-2025\n",
    "    Inspector: SAFETY_TEAM_A\n",
    "    Location: Corporate Headquarters\n",
    "\n",
    "    INSPECTION SUMMARY:\n",
    "    Comprehensive safety and compliance inspection conducted across all floors and departments.\n",
    "    All safety protocols, equipment, and procedures were found to be in full compliance.\n",
    "\n",
    "    FINDINGS:\n",
    "    - All safety equipment properly maintained and accessible\n",
    "    - Emergency exits clear and properly marked\n",
    "    - Chemical storage in full compliance with regulations\n",
    "    - Fire safety systems operational and up to date\n",
    "\n",
    "    VIOLATIONS: None identified\n",
    "    COMPLIANCE STATUS: Fully compliant\n",
    "    Commendation for excellent safety standards maintained.\n",
    "    \"\"\"\n",
    "\n",
    "    examples.append(dspy.Example(\n",
    "        document=clean_inspection,\n",
    "        categories=[\"document\", \"number of violations\", \"list and details of violations\"],\n",
    "        in_csv=\"document,number of violations,list and details of violations\\n32037_ALR10C6BZ_097,3,\\\"Missing safety equipment in Zone A; Improper chemical storage in Building 3; Emergency exit blocked in Warehouse B\\\"\",\n",
    "        last_context=\"Safety equipment and storage violations are recurring issues across sites\",\n",
    "        next_context=\"Safety equipment and storage violations are recurring issues across sites. However, some facilities maintain excellent compliance standards.\",\n",
    "        out_csv=\"document,number of violations,list and details of violations\\n32037_ALR10C6BZ_097,3,\\\"Missing safety equipment in Zone A; Improper chemical storage in Building 3; Emergency exit blocked in Warehouse B\\\"\\n45892_CLN001,0,\\\"None - Fully compliant\\\"\"\n",
    "    ).with_inputs(\"document\", \"categories\", \"in_csv\", \"last_context\"))\n",
    "    \n",
    "    return examples\n",
    "\n",
    "synthetic_examples = create_synthetic_examples()\n",
    "print(f\"Created {len(synthetic_examples)} synthetic examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "define-metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric defined\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation metrics for the doc_analyzer\n",
    "def evaluate_doc_analyzer_output(example, pred, trace=None):\n",
    "    \"\"\"Evaluate the quality of doc_analyzer output\"\"\"\n",
    "    score = 0.0\n",
    "    max_score = 5.0\n",
    "\n",
    "    # 1. Check if CSV format is valid\n",
    "    try:\n",
    "        import io\n",
    "        pd.read_csv(io.StringIO(pred.out_csv))\n",
    "        score += 1.0  # Valid CSV format\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 2. Check if all categories are addressed in CSV headers\n",
    "    try:\n",
    "        csv_data = pd.read_csv(io.StringIO(pred.out_csv))\n",
    "        csv_columns = set(csv_data.columns.tolist())\n",
    "        expected_categories = set(example.categories)\n",
    "        if expected_categories.issubset(csv_columns):\n",
    "            score += 1.0\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 3. Context management - penalize excessive length, reward meaningful updates\n",
    "    context_score = 0.0\n",
    "    if pred.next_context != example.last_context:\n",
    "        # Reward context updates but penalize excessive length\n",
    "        context_length = len(pred.next_context.split())\n",
    "        if 5 <= context_length <= 50:  # Reasonable context length\n",
    "            context_score = 1.0\n",
    "        elif context_length > 50:  # Too long - partial credit\n",
    "            context_score = 0.5\n",
    "        elif context_length > 0:  # Very short but present\n",
    "            context_score = 0.3\n",
    "    score += context_score\n",
    "\n",
    "    # 4. Appropriate use of N/A - check if N/A is used reasonably\n",
    "    try:\n",
    "        csv_data = pd.read_csv(io.StringIO(pred.out_csv))\n",
    "        last_row = csv_data.iloc[-1]  # Get the newly added row\n",
    "\n",
    "        # Count N/A values in the new row\n",
    "        na_count = sum(1 for val in last_row if str(val).strip().upper() == 'N/A')\n",
    "        total_categories = len(example.categories)\n",
    "\n",
    "        # Score based on appropriate N/A usage\n",
    "        if na_count == 0:  # No N/A - good if data is available\n",
    "            score += 1.0\n",
    "        elif na_count < total_categories:  # Some N/A - partial data extracted\n",
    "            score += 0.8\n",
    "        elif na_count == total_categories:  # All N/A - only if truly no data\n",
    "            # This should be rare and only for documents with no extractable data\n",
    "            score += 0.3\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 5. Data extraction quality - check if actual data was extracted when possible\n",
    "    try:\n",
    "        csv_data = pd.read_csv(io.StringIO(pred.out_csv))\n",
    "        last_row = csv_data.iloc[-1]\n",
    "\n",
    "        # Check if meaningful data was extracted (not just filename)\n",
    "        meaningful_data = False\n",
    "        for col in csv_data.columns:\n",
    "            if col != 'document':  # Skip document name column\n",
    "                val = str(last_row[col]).strip()\n",
    "                if val not in ['N/A', '', 'nan'] and len(val) > 1:\n",
    "                    meaningful_data = True\n",
    "                    break\n",
    "        if meaningful_data:\n",
    "            score += 1.0\n",
    "        else:\n",
    "            score += 0.2  # Some credit for proper format even without data\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return score / max_score\n",
    "\n",
    "print(\"Evaluation metric defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "note-about-optimization",
   "metadata": {},
   "source": [
    "## Note about DSPy Example Format\n",
    "\n",
    "The error we encountered earlier was due to improper example formatting. The `with_inputs()` method is crucial for DSPy optimization to work properly. It tells DSPy which fields are inputs vs outputs for the signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alternative-approach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DSPy optimization with BootstrapFewShot...\n",
      "This will automatically optimize the signature using the synthetic examples.\n",
      "BootstrapFewShot optimizer configured\n"
     ]
    }
   ],
   "source": [
    "# Run the optimization with MLflow tracking using BootstrapFewShot\n",
    "from modules import doc_analyzer\n",
    "\n",
    "print(\"Starting DSPy optimization with BootstrapFewShot...\")\n",
    "print(\"This will automatically optimize the signature using the synthetic examples.\")\n",
    "\n",
    "# Create an instance of the doc_analyzer module\n",
    "doc_analyzer_module = dspy.ChainOfThought(doc_analyzer)\n",
    "\n",
    "# Set up the optimizer using BootstrapFewShot\n",
    "optimizer = BootstrapFewShot(\n",
    "    metric=evaluate_doc_analyzer_output,\n",
    "    max_bootstrapped_demos=4,  # Number of examples to bootstrap\n",
    "    max_labeled_demos=2,       # Number of labeled examples to use\n",
    "    max_rounds=2,              # Number of optimization rounds\n",
    "    max_errors=3               # Maximum errors allowed during bootstrapping\n",
    ")\n",
    "\n",
    "print(\"BootstrapFewShot optimizer configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "create-optimized-module",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimizer.compile()...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning optimizer.compile()...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Optimize the signature using BootstrapFewShot\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m optimized_module = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoc_analyzer_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynthetic_examples\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# BootstrapFewShot uses all examples for training\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOptimization complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Test the optimized module\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/.pythonlibs/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:484\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m call_original = update_wrapper_extended(call_original, original)\n\u001b[32m    482\u001b[39m event_logger.log_patch_function_start(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m session.state = \u001b[33m\"\u001b[39m\u001b[33msucceeded\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    487\u001b[39m event_logger.log_patch_function_success(args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/.pythonlibs/lib/python3.11/site-packages/mlflow/dspy/autolog.py:107\u001b[39m, in \u001b[36mautolog.<locals>.patch_fn\u001b[39m\u001b[34m(original, self, *args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Teleprompter):\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_autologging_config(FLAVOR_NAME, \u001b[33m\"\u001b[39m\u001b[33mlog_compiles\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m     program = _compile_fn(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m    110\u001b[39m     \u001b[38;5;66;03m# Save the state of the best model in json format\u001b[39;00m\n\u001b[32m    111\u001b[39m     \u001b[38;5;66;03m# so that users can see the demonstrations and instructions.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/.pythonlibs/lib/python3.11/site-packages/mlflow/dspy/autolog.py:96\u001b[39m, in \u001b[36mautolog.<locals>.patch_fn.<locals>._compile_fn\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m         result = original(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m         result = \u001b[43m_trace_disabled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/.pythonlibs/lib/python3.11/site-packages/mlflow/tracing/provider.py:435\u001b[39m, in \u001b[36mtrace_disabled.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    433\u001b[39m disable()\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     is_func_called, result = \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    437\u001b[39m     enable()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/.pythonlibs/lib/python3.11/site-packages/mlflow/dspy/autolog.py:87\u001b[39m, in \u001b[36mautolog.<locals>.patch_fn.<locals>._trace_disabled_fn\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;129m@trace_disabled\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_trace_disabled_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/.pythonlibs/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:475\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[39m\u001b[34m(*og_args, **og_kwargs)\u001b[39m\n\u001b[32m    472\u001b[39m         original_result = original(*_og_args, **_og_kwargs)\n\u001b[32m    473\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/.pythonlibs/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:426\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[39m\u001b[34m(original_fn, og_args, og_kwargs)\u001b[39m\n\u001b[32m    423\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    424\u001b[39m     event_logger.log_original_function_start(og_args, og_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     original_fn_result = \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m     event_logger.log_original_function_success(og_args, og_kwargs)\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/.pythonlibs/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:472\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[39m\u001b[34m(*_og_args, **_og_kwargs)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001b[32m    469\u001b[39m     disable_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    470\u001b[39m     reroute_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    471\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     original_result = \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/.pythonlibs/lib/python3.11/site-packages/dspy/teleprompt/bootstrap.py:84\u001b[39m, in \u001b[36mBootstrapFewShot.compile\u001b[39m\u001b[34m(self, student, teacher, trainset)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_student_and_teacher(student, teacher)\n\u001b[32m     83\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_predictor_mappings()\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bootstrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.student = \u001b[38;5;28mself\u001b[39m._train()\n\u001b[32m     87\u001b[39m \u001b[38;5;28mself\u001b[39m.student._compiled = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/.pythonlibs/lib/python3.11/site-packages/dspy/teleprompt/bootstrap.py:159\u001b[39m, in \u001b[36mBootstrapFewShot._bootstrap\u001b[39m\u001b[34m(self, max_bootstraps)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m round_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_rounds):\n\u001b[32m    157\u001b[39m     bootstrap_attempts += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bootstrap_one_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_idx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    160\u001b[39m         bootstrapped[example_idx] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/.pythonlibs/lib/python3.11/site-packages/dspy/teleprompt/bootstrap.py:248\u001b[39m, in \u001b[36mBootstrapFewShot._bootstrap_one_example\u001b[39m\u001b[34m(self, example, round_idx)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;66;03m# Update the traces\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, demos \u001b[38;5;129;01min\u001b[39;00m name2traces.items():\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfingerprint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Hasher\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m# If there are multiple traces for the same predictor in the sample example,\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;66;03m# sample 50/50 from the first N-1 traces or the last trace.\u001b[39;00m\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(demos) > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "# Run the optimization with MLflow tracking\n",
    "with mlflow.start_run(run_name=\"doc_analyzer_optimization\") as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"optimizer_type\", \"BootstrapFewShot\")\n",
    "    mlflow.log_param(\"num_examples\", len(synthetic_examples))\n",
    "    mlflow.log_param(\"max_bootstrapped_demos\", 4)\n",
    "    mlflow.log_param(\"max_rounds\", 2)\n",
    "    \n",
    "    print(\"Running optimizer.compile()...\")\n",
    "    \n",
    "    # Optimize the signature using BootstrapFewShot\n",
    "    optimized_module = optimizer.compile(\n",
    "        doc_analyzer_module,\n",
    "        trainset=synthetic_examples  # BootstrapFewShot uses all examples for training\n",
    "    )\n",
    "    \n",
    "    print(\"Optimization complete!\")\n",
    "    \n",
    "    # Test the optimized module\n",
    "    test_doc = \"Sample inspection report with 2 violations: missing fire extinguisher and blocked exit.\"\n",
    "    test_result = optimized_module(\n",
    "        document=test_doc,\n",
    "        categories=[\"document\", \"number of violations\"],\n",
    "        in_csv=\"document,number of violations\",\n",
    "        last_context=\"Testing optimized signature\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTest Results:\")\n",
    "    print(f\"Context: {test_result.next_context}\")\n",
    "    print(f\"CSV Output: {test_result.out_csv}\")\n",
    "    \n",
    "    # Create directory for optimized modules\n",
    "    import os\n",
    "    os.makedirs('optimized_modules', exist_ok=True)\n",
    "    \n",
    "    # Save the optimized module\n",
    "    optimized_module.save('optimized_modules/optimized_doc_analyzer.json')\n",
    "    print(\"\\nOptimized module saved to 'optimized_modules/optimized_doc_analyzer.json'\")\n",
    "    \n",
    "    # Log optimization results\n",
    "    mlflow.log_artifact('optimized_modules/optimized_doc_analyzer.json')\n",
    "    mlflow.log_metric(\"test_context_length\", len(test_result.next_context.split()))\n",
    "    \n",
    "    print(f\"\\nMLflow run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-instructions",
   "metadata": {},
   "source": [
    "## How to Use the Optimized Module\n",
    "\n",
    "The optimized signature has been saved and can be used in your main code. Here are two ways to integrate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usage-examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use the optimized module in your main code\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"USAGE INSTRUCTIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n1. Load the optimized module:\")\n",
    "print(\"   optimized_module = dspy.ChainOfThought(doc_analyzer)\")\n",
    "print(\"   optimized_module.load('optimized_modules/optimized_doc_analyzer.json')\")\n",
    "\n",
    "print(\"\\n2. Or create an optimized trend_analyzer class:\")\n",
    "\n",
    "class optimized_trend_analyzer(dspy.Module):\n",
    "    def __init__(self, use_optimized=True):\n",
    "        super().__init__()\n",
    "        if use_optimized:\n",
    "            from modules import doc_analyzer\n",
    "            self.doc_analyzer_sql = dspy.ChainOfThought(doc_analyzer)\n",
    "            # Load the optimized version\n",
    "            try:\n",
    "                self.doc_analyzer_sql.load('optimized_modules/optimized_doc_analyzer.json')\n",
    "                print(\"✅ Using DSPy-optimized doc_analyzer signature\")\n",
    "            except:\n",
    "                print(\"⚠️  Could not load optimized module, using original\")\n",
    "        else:\n",
    "            from modules import doc_analyzer\n",
    "            self.doc_analyzer_sql = dspy.ChainOfThought(doc_analyzer)\n",
    "            print(\"Using original doc_analyzer signature\")\n",
    "\n",
    "    def forward(self, documents: list[Attachments], categories: list[str], context: str):\n",
    "        doc_summary = \"\"\n",
    "        for document in documents:\n",
    "            result = self.doc_analyzer_sql(\n",
    "                document=document,\n",
    "                categories=categories,\n",
    "                in_csv=doc_summary,\n",
    "                last_context=context\n",
    "            )\n",
    "            context = result.next_context\n",
    "            doc_summary = result.out_csv\n",
    "        return doc_summary, context\n",
    "\n",
    "print(\"\\n✅ Optimized trend_analyzer class created!\")\n",
    "print(\"\\nThe optimization used BootstrapFewShot to:\")\n",
    "print(\"- Improve prompt engineering automatically\")\n",
    "print(\"- Select better few-shot examples\")\n",
    "print(\"- Optimize reasoning patterns\")\n",
    "print(\"\\nThis was done through proper DSPy optimization, not manual signature changes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
