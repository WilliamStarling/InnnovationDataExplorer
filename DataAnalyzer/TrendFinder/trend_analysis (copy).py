"""
Code created by William Starling (williamjonas@comcast.net, 251-680-9048)
dspy code whose goal is to analyze a collection of documents for trends and patterns. It does this by analyzing them one at a time using a dspy signature, and updating a single csv and context file to reflect the new information and trends found in the document. 
"""

#For setting up and creating the DSPy signatures and modules needed to search for trends as a part of the bigger data analysis agent.
import dspy
from attachments.dspy import Attachments
import pandas as pd
import os

"""
dspy signature used to analyze a single document and update the csv file being used for information on the collection of documents as a whole.
inputs: document: Attachments (a document fed through the Attachments API to be analyzed)
        categories: List of strings (the data categories that we want to analyze the document for, such as number of violations, address, etc.)
        in_csv: string (the csv file being used to store information the group of documents as a whole. elements are seperated by commas, new rows by new line characters.)
        last_context: string (Important context of the overall goal and previous steps from other agents.)
outputs: next_context: string (the context used, updated with new information if something important is noticed, such as patterns found.)
         out_csv: string (the csv file updated to include the current documents information.)
"""
class doc_analyzer(dspy.Signature):
    """You will receive a single document from a collection, and using the given categories you will update the csv file to include the current documents's information. You will also take note of any trends and patterns that appear, and add them onto the context output file."""
    document: Attachments = dspy.InputField(
        desc="the current document to analyze")
    categories: list[str] = dspy.InputField(
        desc=
        "the categories to generate a datapoint for based on what's in the document."
    )
    in_csv: str = dspy.InputField(
        desc=
        "The csv file being used to store information about the collection of documents. elements are seperated by commas, new rows by new line characters."
    )
    last_context: str = dspy.InputField(
        desc=
        "Important context of the overall goal and previous steps from other agents."
    )
    next_context: str = dspy.OutputField(
        desc=
        "The input context passed on, where new information is optionally added on if thought to be important. New context, if present at all, should be brief to ensure the overall context doesn't get too long."
    )
    out_csv: str = dspy.OutputField(
        desc=
        "The csv file updated to include the current documents information. elements are seperated by commas, new rows by new line characters."
    )

"""
dspy module use to analyze a collection of documents as a whole. documents must be passed in as a list of Attachments objects.
inputs: documents: list of Attachments (a list of documents to be analyzed, as attachment objects. see trend_test.py for an example of how it's used.)
        categories: list of strings (a list of categories that exists as strings. these are used as a guide to know what to look for in each document.)
        context: string (the context of the overall goal and previous steps from other agents.)
doc_sumarry: string (csv file formatted string with the information from each category filled out for each document.)
context: string: (the context of the instructions, previous agents notes, and this agents notes.)
"""
class trend_analyzer(dspy.Module):

    def __init__(self):
        super().__init__()
        self.doc_analyzer_sql = dspy.ChainOfThought(doc_analyzer)

    def forward(self, documents: list[Attachments], categories: list[str],
                context: str):
        doc_summary = ""
        for document in documents:
            result = self.doc_analyzer_sql(document=document,
                                           categories=categories,
                                           in_csv=doc_summary,
                                           last_context=context)
            context = result.next_context
            doc_summary = result.out_csv
        #print(doc_summary)
        return doc_summary, context


# ====== CODE FROM THIS POINT ON WAS GENERATED BY CLAUDE AI FOR THE SAKE OF PROVIDING A COMMAND LINE UI ======

def get_user_input():
    """Get user input for document paths and categories"""
    print("=" * 60)
    print("ğŸ” TREND ANALYZER - COMMAND LINE INTERFACE")
    print("=" * 60)
    
    # Get document paths
    print("\nğŸ“„ DOCUMENT PATHS:")
    print("Enter document paths (one per line, empty line to finish):")
    document_paths = []
    while True:
        path = input("Document path: ").strip()
        if not path:
            break
        if not os.path.exists(path):
            print(f"âš ï¸  Warning: File '{path}' does not exist!")
            continue_anyway = input("Continue anyway? (y/n): ").lower().strip()
            if continue_anyway != 'y':
                continue
        document_paths.append(path)
    
    if not document_paths:
        print("âŒ No document paths provided. Exiting...")
        return None, None
    
    print(f"âœ… Added {len(document_paths)} document(s)")
    
    # Get categories
    print("\nğŸ·ï¸  CATEGORIES:")
    print("Enter categories to analyze (one per line, empty line to finish):")
    categories = []
    while True:
        category = input("Category: ").strip()
        if not category:
            break
        categories.append(category)
    
    if not categories:
        print("âŒ No categories provided. Exiting...")
        return None, None
    
    print(f"âœ… Added {len(categories)} categor(ies): {', '.join(categories)}")
    
    return document_paths, categories


def run_command_line_analysis():
    """Run the trend analyzer from command line"""
    import os
    
    # Get user input
    document_paths, categories = get_user_input()
    if not document_paths or not categories:
        return
    
    # Setup DSPy with Gemini
    print("\nğŸ¤– SETTING UP AI MODEL:")
    api_key = os.environ.get('paul2')
    if not api_key:
        print("âŒ Error: 'paul2' environment variable not found!")
        print("Please set your Gemini API key in the environment variables.")
        return
    
    try:
        lm = dspy.LM('gemini/gemini-2.5-flash', api_key=api_key, max_tokens=8000)
        dspy.configure(lm=lm)
        print("âœ… AI model configured successfully")
    except Exception as e:
        print(f"âŒ Error setting up AI model: {e}")
        return
    
    # Create Attachments objects from document paths
    print("\nğŸ“ LOADING DOCUMENTS:")
    documents = []
    for path in document_paths:
        try:
            attachment = Attachments(path)
            documents.append(attachment)
            print(f"âœ… Loaded: {path}")
        except Exception as e:
            print(f"âŒ Error loading '{path}': {e}")
    
    if not documents:
        print("âŒ No documents could be loaded. Exiting...")
        return
    
    # Set default context
    default_context = "Search the provided documents for information that fits in the provided categories."
    
    # Run trend analysis
    print("\nğŸ” RUNNING ANALYSIS:")
    print("This may take a few moments...")
    
    try:
        analyzer = trend_analyzer()
        csv_result, final_context = analyzer.forward(
            documents=documents,
            categories=categories,
            context=default_context
        )
        
        print("\n" + "=" * 60)
        print("ğŸ“Š ANALYSIS RESULTS")
        print("=" * 60)
        
        # Display CSV results
        print("\nğŸ“‹ GENERATED CSV DATA:")
        if csv_result:
            csv_lines = csv_result.split('\n')
            for i, line in enumerate(csv_lines):
                if line.strip():
                    print(f"   {line}")
            print(f"\nâœ… Generated {len([l for l in csv_lines if l.strip()]) - 1} data rows")
        else:
            print("   No data generated")
        
        # Display final context
        print(f"\nğŸ’­ FINAL CONTEXT:")
        if final_context:
            context_preview = final_context[:500]
            if len(final_context) > 500:
                context_preview += "..."
            print(f"   {context_preview}")
        
        # Ask if user wants to save results
        print(f"\nğŸ’¾ SAVE RESULTS:")
        save_choice = input("Save results to file? (y/n): ").lower().strip()
        if save_choice == 'y':
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Save CSV
            csv_filename = f"trend_analysis_{timestamp}.csv"
            with open(csv_filename, 'w', encoding='utf-8') as f:
                f.write(csv_result)
            
            # Save context
            context_filename = f"trend_analysis_{timestamp}_context.txt"
            with open(context_filename, 'w', encoding='utf-8') as f:
                f.write(f"Analysis Context:\n{final_context}\n\n")
                f.write(f"Categories Used: {', '.join(categories)}\n")
                f.write(f"Documents Analyzed: {len(documents)}\n")
                f.write(f"Document Paths:\n")
                for path in document_paths:
                    f.write(f"  - {path}\n")
            
            print(f"âœ… Results saved:")
            print(f"   ğŸ“Š CSV: {csv_filename}")
            print(f"   ğŸ“„ Context: {context_filename}")
        
        print("\nğŸ‰ Analysis completed successfully!")
        
    except Exception as e:
        print(f"âŒ Error during analysis: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    run_command_line_analysis()
