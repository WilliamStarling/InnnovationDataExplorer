{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa3aa23-e2e2-4a6b-94e9-dfb4271bf2b0",
   "metadata": {},
   "source": [
    "Notebook for optimizing the trend analyzer code.\n",
    "To run the notebook, run the command \"jupyter notebook --ip=0.0.0.0 --port=5024 --allow-root --no-browser\". Then open the webpage that opens in replit in a new tab, and enter the token for the server you find from the command \"jupter server list\". If you enter the token in the replit preview it will give you a 403 error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "868f8830-df75-40f4-844e-371030acf6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSPy version: 3.0.0b2\n"
     ]
    }
   ],
   "source": [
    "#import necessary modules\n",
    "from modules import *\n",
    "import os\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dd921eb-5851-448a-9dd4-aa8ece445a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/23 22:28:49 INFO mlflow.tracking.fluent: Experiment with name 'TrendFinderOptimizer' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "#setup mlflow\n",
    "mlflow_tracking_uri = \"../../mlflow/experiments\"\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "mlflow.set_experiment(\"TrendFinderOptimizer\")\n",
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23fb65a5-c9f6-453d-9284-fad6223d3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup dspy\n",
    "api_key = os.environ['paul2']\n",
    "lm = dspy.LM('gemini/gemini-2.5-flash', api_key=api_key, max_tokens=8000)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f15e81f-2189-4043-a8b7-2aebee69e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_trends = trend_analyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimization-intro",
   "metadata": {},
   "source": [
    "## DSPy Optimization for doc_analyzer\n",
    "\n",
    "Since we don't have labeled training data, we'll use DSPy's signature optimization and prompt engineering techniques to improve the `doc_analyzer` signature performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "setup-optimization",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SignatureOptimizer' from 'dspy.teleprompt' (/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/dspy/teleprompt/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import optimization modules\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mteleprompt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BootstrapFewShot, SignatureOptimizer\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Evaluate\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'SignatureOptimizer' from 'dspy.teleprompt' (/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/dspy/teleprompt/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Import optimization modules\n",
    "import dspy\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from dspy.evaluate import Evaluate\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "create-synthetic-examples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 synthetic examples\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic examples for different document types and categories\n",
    "# This helps DSPy understand the expected input/output patterns\n",
    "\n",
    "def create_synthetic_examples():\n",
    "    examples = []\n",
    "    \n",
    "    # Example 1: Realistic inspection report with lengthy content\n",
    "    inspection_report_1 = \"\"\"\n",
    "    INSPECTION REPORT - Document ID: 32037 ALR10C6BZ 097\n",
    "    Date: 07-10-2025\n",
    "    Inspector: AEPACS\n",
    "    Location: Industrial Site NA\n",
    "\n",
    "    SUMMARY OF INSPECTION:\n",
    "    This inspection was conducted in accordance with safety regulations and compliance standards.\n",
    "    The facility was evaluated for adherence to safety protocols, equipment maintenance, and regulatory compliance.\n",
    "\n",
    "    VIOLATIONS IDENTIFIED:\n",
    "    1. Missing safety equipment in Zone A - Safety harnesses not available at designated stations\n",
    "    2. Improper chemical storage in Building 3 - Hazardous materials not properly labeled or contained\n",
    "    3. Emergency exit blocked by equipment in Warehouse B\n",
    "\n",
    "    RECOMMENDATIONS:\n",
    "    - Immediate procurement and installation of safety equipment\n",
    "    - Proper labeling and containment of all hazardous materials\n",
    "    - Clear all emergency exits of obstructions\n",
    "\n",
    "    COMPLIANCE STATUS: Non-compliant - 3 violations found\n",
    "    Next inspection scheduled for 08-15-2025\n",
    "    \"\"\"\n",
    "\n",
    "    examples.append(dspy.Example(\n",
    "        document=inspection_report_1,\n",
    "        categories=[\"document\", \"number of violations\", \"list and details of violations\"],\n",
    "        in_csv=\"\",\n",
    "        last_context=\"Analyzing safety inspection reports for compliance trends\",\n",
    "        next_context=\"Safety equipment and storage violations are recurring issues across sites\",\n",
    "        out_csv=\"document,number of violations,list and details of violations\\n32037_ALR10C6BZ_097.pdf,3,Missing safety equipment in Zone A; Improper chemical storage in Building 3; Emergency exit blocked in Warehouse B\"\n",
    "    ))\n",
    "\n",
    "    # Example 2: Financial document with some missing categories\n",
    "    financial_report = \"\"\"\n",
    "    QUARTERLY FINANCIAL STATEMENT - Q3 2025\n",
    "    Company: TechCorp Industries\n",
    "\n",
    "    REVENUE BREAKDOWN:\n",
    "    Product Sales: $850,000\n",
    "    Service Revenue: $320,000\n",
    "    Total Revenue: $1,170,000\n",
    "\n",
    "    OPERATIONAL EXPENSES:\n",
    "    Salaries and Benefits: $450,000\n",
    "    Equipment and Maintenance: $120,000\n",
    "    Marketing: $85,000\n",
    "    Total Expenses: $655,000\n",
    "\n",
    "    NET PROFIT: $515,000\n",
    "\n",
    "    Note: Employee count data not available in this quarterly report.\n",
    "    Tax information will be provided in annual filing.\n",
    "    \"\"\"\n",
    "\n",
    "    examples.append(dspy.Example(\n",
    "        document=financial_report,\n",
    "        categories=[\"revenue\", \"expenses\", \"profit\", \"employee_count\", \"tax_rate\"],\n",
    "        in_csv=\"\",\n",
    "        last_context=\"Processing quarterly financial reports for trend analysis\",\n",
    "        next_context=\"Q3 shows strong profitability, employee data consistently missing from quarterly reports\",\n",
    "        out_csv=\"document,revenue,expenses,profit,employee_count,tax_rate\\nQ3_2025_financial.pdf,$1170000,$655000,$515000,N/A,N/A\"\n",
    "    ))\n",
    "\n",
    "    # Example 3: Document with no violations (testing N/A handling)\n",
    "    clean_inspection = \"\"\"\n",
    "    INSPECTION REPORT - Document ID: 45892 CLN001\n",
    "    Date: 07-12-2025\n",
    "    Inspector: SAFETY_TEAM_A\n",
    "    Location: Corporate Headquarters\n",
    "\n",
    "    INSPECTION SUMMARY:\n",
    "    Comprehensive safety and compliance inspection conducted across all floors and departments.\n",
    "    All safety protocols, equipment, and procedures were found to be in full compliance.\n",
    "\n",
    "    FINDINGS:\n",
    "    - All safety equipment properly maintained and accessible\n",
    "    - Emergency exits clear and properly marked\n",
    "    - Chemical storage in full compliance with regulations\n",
    "    - Fire safety systems operational and up to date\n",
    "\n",
    "    VIOLATIONS: None identified\n",
    "    COMPLIANCE STATUS: Fully compliant\n",
    "    Commendation for excellent safety standards maintained.\n",
    "    \"\"\"\n",
    "\n",
    "    examples.append(dspy.Example(\n",
    "        document=clean_inspection,\n",
    "        categories=[\"document\", \"number of violations\", \"list and details of violations\"],\n",
    "        in_csv=\"document,number of violations,list and details of violations\\n32037_ALR10C6BZ_097.pdf,3,Missing safety equipment in Zone A; Improper chemical storage in Building 3; Emergency exit blocked in Warehouse B\",\n",
    "        last_context=\"Safety equipment and storage violations are recurring issues across sites\",\n",
    "        next_context=\"Some sites maintain excellent compliance standards with zero violations\",\n",
    "        out_csv=\"document,number of violations,list and details of violations\\n32037_ALR10C6BZ_097.pdf,3,Missing safety equipment in Zone A; Improper chemical storage in Building 3; Emergency exit blocked in Warehouse B\\n45892_CLN001.pdf,0,N/A\"\n",
    "    ))\n",
    "    \n",
    "    return examples\n",
    "\n",
    "synthetic_examples = create_synthetic_examples()\n",
    "print(f\"Created {len(synthetic_examples)} synthetic examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "define-metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric defined\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation metrics for the doc_analyzer\n",
    "def evaluate_doc_analyzer_output(example, pred, trace=None):\n",
    "    \"\"\"Evaluate the quality of doc_analyzer output\"\"\"\n",
    "    score = 0.0\n",
    "    max_score = 5.0\n",
    "\n",
    "    # 1. Check if CSV format is valid\n",
    "    try:\n",
    "        import io\n",
    "        pd.read_csv(io.StringIO(pred.out_csv))\n",
    "        score += 1.0  # Valid CSV format\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 2. Check if all categories are addressed in CSV headers\n",
    "    try:\n",
    "        csv_data = pd.read_csv(io.StringIO(pred.out_csv))\n",
    "        csv_columns = set(csv_data.columns.tolist())\n",
    "        expected_categories = set(example.categories)\n",
    "        if expected_categories.issubset(csv_columns):\n",
    "            score += 1.0\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 3. Context management - penalize excessive length, reward meaningful updates\n",
    "    context_score = 0.0\n",
    "    if pred.next_context != example.last_context:\n",
    "        # Reward context updates but penalize excessive length\n",
    "        context_length = len(pred.next_context.split())\n",
    "        if 5 <= context_length <= 50:  # Reasonable context length\n",
    "            context_score = 1.0\n",
    "        elif context_length > 50:  # Too long - partial credit\n",
    "            context_score = 0.5\n",
    "        elif context_length > 0:  # Very short but present\n",
    "            context_score = 0.3\n",
    "    score += context_score\n",
    "\n",
    "    # 4. Appropriate use of N/A - check if N/A is used reasonably\n",
    "    try:\n",
    "        csv_data = pd.read_csv(io.StringIO(pred.out_csv))\n",
    "        last_row = csv_data.iloc[-1]  # Get the newly added row\n",
    "\n",
    "        # Count N/A values in the new row\n",
    "        na_count = sum(1 for val in last_row if str(val).strip().upper() == 'N/A')\n",
    "        total_categories = len(example.categories)\n",
    "\n",
    "        # Score based on appropriate N/A usage\n",
    "        if na_count == 0:  # No N/A - good if data is available\n",
    "            score += 1.0\n",
    "        elif na_count < total_categories:  # Some N/A - partial data extracted\n",
    "            score += 0.8\n",
    "        elif na_count == total_categories:  # All N/A - only if truly no data\n",
    "            # This should be rare and only for documents with no extractable data\n",
    "            score += 0.3\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 5. Data extraction quality - check if actual data was extracted when possible\n",
    "    try:\n",
    "        csv_data = pd.read_csv(io.StringIO(pred.out_csv))\n",
    "        last_row = csv_data.iloc[-1]\n",
    "\n",
    "        # Check if meaningful data was extracted (not just filename)\n",
    "        meaningful_data = False\n",
    "        for col in csv_data.columns:\n",
    "            if col != 'document':  # Skip document name column\n",
    "                val = str(last_row[col]).strip()\n",
    "                if val not in ['N/A', '', 'nan'] and len(val) > 1:\n",
    "                    meaningful_data = True\n",
    "                    break\n",
    "\n",
    "        if meaningful_data:\n",
    "            score += 1.0\n",
    "        else:\n",
    "            score += 0.2  # Some credit for proper format even without data\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return score / max_score\n",
    "\n",
    "print(\"Evaluation metric defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "optimize-signature",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SignatureOptimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m doc_analyzer_module = dspy.ChainOfThought(doc_analyzer)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Set up the optimizer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m optimizer = \u001b[43mSignatureOptimizer\u001b[49m(\n\u001b[32m      9\u001b[39m     metric=evaluate_doc_analyzer_output,\n\u001b[32m     10\u001b[39m     breadth=\u001b[32m10\u001b[39m,  \u001b[38;5;66;03m# Number of candidate prompts to generate\u001b[39;00m\n\u001b[32m     11\u001b[39m     depth=\u001b[32m2\u001b[39m,     \u001b[38;5;66;03m# Number of optimization rounds\u001b[39;00m\n\u001b[32m     12\u001b[39m     init_temperature=\u001b[32m1.4\u001b[39m,\n\u001b[32m     13\u001b[39m     verbose=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting signature optimization...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mThis may take several minutes as it tests different prompt variations.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'SignatureOptimizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Optimize the doc_analyzer signature\n",
    "# We'll use BootstrapFewShot to improve the prompt and reasoning\n",
    "\n",
    "# Create an instance of the doc_analyzer module\n",
    "doc_analyzer_module = dspy.ChainOfThought(doc_analyzer)\n",
    "\n",
    "# Set up the optimizer using BootstrapFewShot\n",
    "optimizer = BootstrapFewShot(\n",
    "    metric=evaluate_doc_analyzer_output,\n",
    "    max_bootstrapped_demos=4,  # Number of examples to bootstrap\n",
    "    max_labeled_demos=2,       # Number of labeled examples to use\n",
    "    max_rounds=2,              # Number of optimization rounds\n",
    "    max_errors=3               # Maximum errors allowed during bootstrapping\n",
    ")\n",
    "\n",
    "print(\"Starting signature optimization with BootstrapFewShot...\")\n",
    "print(\"This may take several minutes as it tests different prompt variations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "run-optimization",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m mlflow.log_param(\u001b[33m\"\u001b[39m\u001b[33mdepth\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Optimize the signature\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m optimized_module = \u001b[43moptimizer\u001b[49m.compile(\n\u001b[32m     11\u001b[39m     doc_analyzer_module,\n\u001b[32m     12\u001b[39m     trainset=synthetic_examples[:\u001b[32m2\u001b[39m],  \u001b[38;5;66;03m# Use first 2 for training\u001b[39;00m\n\u001b[32m     13\u001b[39m     valset=synthetic_examples[\u001b[32m2\u001b[39m:],    \u001b[38;5;66;03m# Use remaining for validation\u001b[39;00m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Log the optimized signature\u001b[39;00m\n\u001b[32m     17\u001b[39m mlflow.log_text(\u001b[38;5;28mstr\u001b[39m(optimized_module.signature), \u001b[33m\"\u001b[39m\u001b[33moptimized_signature.txt\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the optimization with MLflow tracking\n",
    "with mlflow.start_run(run_name=\"doc_analyzer_optimization\") as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"optimizer_type\", \"BootstrapFewShot\")\n",
    "    mlflow.log_param(\"num_examples\", len(synthetic_examples))\n",
    "    mlflow.log_param(\"max_bootstrapped_demos\", 4)\n",
    "    mlflow.log_param(\"max_rounds\", 2)\n",
    "    \n",
    "    # Optimize the signature\n",
    "    optimized_module = optimizer.compile(\n",
    "        doc_analyzer_module,\n",
    "        trainset=synthetic_examples  # BootstrapFewShot uses all examples for training\n",
    "    )\n",
    "    \n",
    "    # Log the optimized signature\n",
    "    mlflow.log_text(str(optimized_module.signature), \"optimized_signature.txt\")\n",
    "    \n",
    "    print(\"Optimization completed!\")\n",
    "    print(f\"Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "test-optimization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Original Module:\n",
      "========================================\n",
      "Context: Analyzing safety inspection reports for compliance trends. This document indicates non-compliance with 3 violations.\n",
      "CSV: document,number of violations,list and details of violations\n",
      "32037 ALR10C6BZ 097,3,\"1. Missing safety equipment in Zone A - Safety harnesses not available at designated stations; 2. Improper chemical storage in Building 3 - Hazardous materials not properly labeled or contained; 3. Emergency exit blocked by equipment in Warehouse B\"\n",
      "Score: 1.0\n",
      "\n",
      "Testing Optimized Module:\n",
      "========================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimized_module' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTesting Optimized Module:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m optimized_result = \u001b[43moptimized_module\u001b[49m(\n\u001b[32m     19\u001b[39m     document=test_example.document,\n\u001b[32m     20\u001b[39m     categories=test_example.categories,\n\u001b[32m     21\u001b[39m     in_csv=test_example.in_csv,\n\u001b[32m     22\u001b[39m     last_context=test_example.last_context\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mContext: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimized_result.next_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCSV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimized_result.out_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'optimized_module' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the optimized module with a sample\n",
    "test_example = synthetic_examples[0]\n",
    "\n",
    "print(\"Testing Original Module:\")\n",
    "print(\"=\" * 40)\n",
    "original_result = doc_analyzer_module(\n",
    "    document=test_example.document,\n",
    "    categories=test_example.categories,\n",
    "    in_csv=test_example.in_csv,\n",
    "    last_context=test_example.last_context\n",
    ")\n",
    "print(f\"Context: {original_result.next_context}\")\n",
    "print(f\"CSV: {original_result.out_csv}\")\n",
    "print(f\"Score: {evaluate_doc_analyzer_output(test_example, original_result)}\")\n",
    "\n",
    "print(\"\\nTesting Optimized Module:\")\n",
    "print(\"=\" * 40)\n",
    "optimized_result = optimized_module(\n",
    "    document=test_example.document,\n",
    "    categories=test_example.categories,\n",
    "    in_csv=test_example.in_csv,\n",
    "    last_context=test_example.last_context\n",
    ")\n",
    "print(f\"Context: {optimized_result.next_context}\")\n",
    "print(f\"CSV: {optimized_result.out_csv}\")\n",
    "print(f\"Score: {evaluate_doc_analyzer_output(test_example, optimized_result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-optimized-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimized module for use in the main application\n",
    "import os\n",
    "\n",
    "# Create optimized modules directory if it doesn't exist\n",
    "os.makedirs(\"optimized_modules\", exist_ok=True)\n",
    "\n",
    "# Save the optimized module using DSPy's official save method\n",
    "optimized_module.save(\"optimized_modules/optimized_doc_analyzer.json\")\n",
    "\n",
    "# Also save the signature as text for inspection\n",
    "with open(\"optimized_modules/optimized_signature.txt\", \"w\") as f:\n",
    "    f.write(str(optimized_module.signature))\n",
    "\n",
    "print(\"Optimized module saved using DSPy's official .save() method!\")\n",
    "print(\"You can load it in your main application using:\")\n",
    "print(\"import dspy\")\n",
    "print(\"from modules import doc_analyzer\")\n",
    "print(\"optimized_module = dspy.ChainOfThought(doc_analyzer)\")\n",
    "print(\"optimized_module.load('optimized_modules/optimized_doc_analyzer.json')\")\n",
    "print(\"\")\n",
    "print(\"Or integrate it into your trend_analyzer class by modifying the __init__ method:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-with-real-documents",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the optimized module with your actual documents\n",
    "print(\"Testing with real documents from your training data...\")\n",
    "\n",
    "# Use the same setup as in your test.py\n",
    "categories = [\n",
    "    \"document\", \"number of violations\", \"list and details of violations\"\n",
    "]\n",
    "\n",
    "documents = []\n",
    "documents.append(\n",
    "    Attachments(\n",
    "        \"TrainingData/32037 ALR10C6BZ 097 07-10-2025 INSPR AEPACS NA.pdf\"))\n",
    "\n",
    "# Create an optimized trend analyzer\n",
    "class optimized_trend_analyzer(dspy.Module):\n",
    "    def __init__(self, optimized_doc_analyzer):\n",
    "        super().__init__()\n",
    "        self.doc_analyzer_sql = optimized_doc_analyzer\n",
    "\n",
    "    def forward(self, documents: list[Attachments], categories: list[str], context: str):\n",
    "        doc_summary = \"\"\n",
    "        for document in documents:\n",
    "            result = self.doc_analyzer_sql(\n",
    "                document=document,\n",
    "                categories=categories,\n",
    "                in_csv=doc_summary,\n",
    "                last_context=context\n",
    "            )\n",
    "            context = result.next_context\n",
    "            doc_summary = result.out_csv\n",
    "        return doc_summary, context\n",
    "\n",
    "# Test with optimized module\n",
    "optimized_analyzer = optimized_trend_analyzer(optimized_module)\n",
    "result, context = optimized_analyzer(\n",
    "    documents=documents[:1],  # Test with first document\n",
    "    categories=categories,\n",
    "    context=\"\"\n",
    ")\n",
    "\n",
    "print(\"Optimized Result:\")\n",
    "print(f\"CSV Output: {result}\")\n",
    "print(f\"Context: {context}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimization-summary",
   "metadata": {},
   "source": [
    "## Loading the Optimized Module\n",
    "\n",
    "Here's how to integrate the optimized module into your existing code:\n",
    "\n",
    "```python\n",
    "# Option 1: Load and use directly\n",
    "import dspy\n",
    "from modules import doc_analyzer\n",
    "\n",
    "# Create and load optimized module\n",
    "optimized_doc_analyzer = dspy.ChainOfThought(doc_analyzer)\n",
    "optimized_doc_analyzer.load('optimized_modules/optimized_doc_analyzer.json')\n",
    "\n",
    "# Option 2: Modify your trend_analyzer class\n",
    "class optimized_trend_analyzer(dspy.Module):\n",
    "    def __init__(self, use_optimized=True):\n",
    "        super().__init__()\n",
    "        self.doc_analyzer_sql = dspy.ChainOfThought(doc_analyzer)\n",
    "        if use_optimized:\n",
    "            try:\n",
    "                self.doc_analyzer_sql.load('optimized_modules/optimized_doc_analyzer.json')\n",
    "                print(\"Loaded optimized doc_analyzer module\")\n",
    "            except FileNotFoundError:\n",
    "                print(\"Optimized module not found, using default\")\n",
    "\n",
    "    def forward(self, documents: list[Attachments], categories: list[str], context: str):\n",
    "        # Same implementation as before\n",
    "        doc_summary = \"\"\n",
    "        for document in documents:\n",
    "            result = self.doc_analyzer_sql(\n",
    "                document=document,\n",
    "                categories=categories,\n",
    "                in_csv=doc_summary,\n",
    "                last_context=context\n",
    "            )\n",
    "            context = result.next_context\n",
    "            doc_summary = result.out_csv\n",
    "        return doc_summary, context\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
