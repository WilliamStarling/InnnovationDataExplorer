
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa3aa23-e2e2-4a6b-94e9-dfb4271bf2b0",
   "metadata": {},
   "source": [
    "Notebook for optimizing the trend analyzer code.\n",
    "To run the notebook, run the command \"jupyter notebook --ip=0.0.0.0 --port=5000 --allow-root --no-browser\". Then open the webpage that opens in replit in a new tab, and enter the token for the server you find from the command \"jupter server list\". If you enter the token in the replit preview it will give you a 403 error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f8830-df75-40f4-844e-371030acf6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "from modules import *\n",
    "import os\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd921eb-5851-448a-9dd4-aa8ece445a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup mlflow\n",
    "mlflow_tracking_uri = \"../../mlflow/experiments\"\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "mlflow.set_experiment(\"TrendFinderOptimizer\")\n",
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb65a5-c9f6-453d-9284-fad6223d3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup dspy\n",
    "api_key = os.environ['paul2']\n",
    "lm = dspy.LM('gemini/gemini-2.5-flash', api_key=api_key, max_tokens=8000)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimization-intro",
   "metadata": {},
   "source": [
    "## DSPy Optimization for doc_analyzer\n",
    "\n",
    "Since we don't have labeled training data, we'll use DSPy's signature optimization and prompt engineering techniques to improve the `doc_analyzer` signature performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import optimization modules\n",
    "import dspy\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from dspy.evaluate import Evaluate\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-synthetic-examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic examples for different document types and categories\n",
    "# This helps DSPy understand the expected input/output patterns\n",
    "\n",
    "def create_synthetic_examples():\n",
    "    examples = []\n",
    "    \n",
    "    # Example 1: Realistic inspection report with lengthy content\n",
    "    inspection_report_1 = \"\"\"\n",
    "    INSPECTION REPORT - Document ID: 32037 ALR10C6BZ 097\n",
    "    Date: 07-10-2025\n",
    "    Inspector: AEPACS\n",
    "    Location: Industrial Site NA\n",
    "\n",
    "    SUMMARY OF INSPECTION:\n",
    "    This inspection was conducted in accordance with safety regulations and compliance standards.\n",
    "    The facility was evaluated for adherence to safety protocols, equipment maintenance, and regulatory compliance.\n",
    "\n",
    "    VIOLATIONS IDENTIFIED:\n",
    "    1. Missing safety equipment in Zone A - Safety harnesses not available at designated stations\n",
    "    2. Improper chemical storage in Building 3 - Hazardous materials not properly labeled or contained\n",
    "    3. Emergency exit blocked by equipment in Warehouse B\n",
    "\n",
    "    RECOMMENDATIONS:\n",
    "    - Immediate procurement and installation of safety equipment\n",
    "    - Proper labeling and containment of all hazardous materials\n",
    "    - Clear all emergency exits of obstructions\n",
    "\n",
    "    COMPLIANCE STATUS: Non-compliant - 3 violations found\n",
    "    Next inspection scheduled for 08-15-2025\n",
    "    \"\"\"\n",
    "\n",
    "    examples.append(dspy.Example(\n",
    "        document=inspection_report_1,\n",
    "        categories=[\"document\", \"number of violations\", \"list and details of violations\"],\n",
    "        in_csv=\"\",\n",
    "        last_context=\"Analyzing safety inspection reports for compliance trends\"\n",
    "    ).with_inputs(\"document\", \"categories\", \"in_csv\", \"last_context\"))\n",
    "\n",
    "    # Example 2: Financial document with some missing categories\n",
    "    financial_report = \"\"\"\n",
    "    QUARTERLY FINANCIAL STATEMENT - Q3 2025\n",
    "    Company: TechCorp Industries\n",
    "\n",
    "    REVENUE BREAKDOWN:\n",
    "    Product Sales: $850,000\n",
    "    Service Revenue: $320,000\n",
    "    Total Revenue: $1,170,000\n",
    "\n",
    "    OPERATIONAL EXPENSES:\n",
    "    Salaries and Benefits: $450,000\n",
    "    Equipment and Maintenance: $120,000\n",
    "    Marketing: $85,000\n",
    "    Total Expenses: $655,000\n",
    "\n",
    "    NET PROFIT: $515,000\n",
    "\n",
    "    Note: Employee count data not available in this quarterly report.\n",
    "    Tax information will be provided in annual filing.\n",
    "    \"\"\"\n",
    "\n",
    "    examples.append(dspy.Example(\n",
    "        document=financial_report,\n",
    "        categories=[\"revenue\", \"expenses\", \"profit\", \"employee_count\", \"tax_rate\"],\n",
    "        in_csv=\"\",\n",
    "        last_context=\"Processing quarterly financial reports for trend analysis\"\n",
    "    ).with_inputs(\"document\", \"categories\", \"in_csv\", \"last_context\"))\n",
    "\n",
    "    # Example 3: Document with no violations (testing N/A handling)\n",
    "    clean_inspection = \"\"\"\n",
    "    INSPECTION REPORT - Document ID: 45892 CLN001\n",
    "    Date: 07-12-2025\n",
    "    Inspector: SAFETY_TEAM_A\n",
    "    Location: Corporate Headquarters\n",
    "\n",
    "    INSPECTION SUMMARY:\n",
    "    Comprehensive safety and compliance inspection conducted across all floors and departments.\n",
    "    All safety protocols, equipment, and procedures were found to be in full compliance.\n",
    "\n",
    "    FINDINGS:\n",
    "    - All safety equipment properly maintained and accessible\n",
    "    - Emergency exits clear and properly marked\n",
    "    - Chemical storage in full compliance with regulations\n",
    "    - Fire safety systems operational and up to date\n",
    "\n",
    "    VIOLATIONS: None identified\n",
    "    COMPLIANCE STATUS: Fully compliant\n",
    "    Commendation for excellent safety standards maintained.\n",
    "    \"\"\"\n",
    "\n",
    "    examples.append(dspy.Example(\n",
    "        document=clean_inspection,\n",
    "        categories=[\"document\", \"number of violations\", \"list and details of violations\"],\n",
    "        in_csv=\"document,number of violations,list and details of violations\\n32037_ALR10C6BZ_097.pdf,3,Missing safety equipment in Zone A; Improper chemical storage in Building 3; Emergency exit blocked in Warehouse B\",\n",
    "        last_context=\"Safety equipment and storage violations are recurring issues across sites\"\n",
    "    ).with_inputs(\"document\", \"categories\", \"in_csv\", \"last_context\"))\n",
    "    \n",
    "    return examples\n",
    "\n",
    "synthetic_examples = create_synthetic_examples()\n",
    "print(f\"Created {len(synthetic_examples)} synthetic examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics for the doc_analyzer\n",
    "def evaluate_doc_analyzer_output(example, pred, trace=None):\n",
    "    \"\"\"Evaluate the quality of doc_analyzer output\"\"\"\n",
    "    score = 0.0\n",
    "    max_score = 5.0\n",
    "\n",
    "    # 1. Check if CSV format is valid\n",
    "    try:\n",
    "        import io\n",
    "        pd.read_csv(io.StringIO(pred.out_csv))\n",
    "        score += 1.0  # Valid CSV format\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 2. Check if all categories are addressed in CSV headers\n",
    "    try:\n",
    "        csv_data = pd.read_csv(io.StringIO(pred.out_csv))\n",
    "        csv_columns = set(csv_data.columns.tolist())\n",
    "        expected_categories = set(example.categories)\n",
    "        if expected_categories.issubset(csv_columns):\n",
    "            score += 1.0\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 3. Context management - penalize excessive length, reward meaningful updates\n",
    "    context_score = 0.0\n",
    "    if pred.next_context != example.last_context:\n",
    "        # Reward context updates but penalize excessive length\n",
    "        context_length = len(pred.next_context.split())\n",
    "        if 5 <= context_length <= 50:  # Reasonable context length\n",
    "            context_score = 1.0\n",
    "        elif context_length > 50:  # Too long - partial credit\n",
    "            context_score = 0.5\n",
    "        elif context_length > 0:  # Very short but present\n",
    "            context_score = 0.3\n",
    "    score += context_score\n",
    "\n",
    "    # 4. Appropriate use of N/A - check if N/A is used reasonably\n",
    "    try:\n",
    "        csv_data = pd.read_csv(io.StringIO(pred.out_csv))\n",
    "        last_row = csv_data.iloc[-1]  # Get the newly added row\n",
    "\n",
    "        # Count N/A values in the new row\n",
    "        na_count = sum(1 for val in last_row if str(val).strip().upper() == 'N/A')\n",
    "        total_categories = len(example.categories)\n",
    "\n",
    "        # Score based on appropriate N/A usage\n",
    "        if na_count == 0:  # No N/A - good if data is available\n",
    "            score += 1.0\n",
    "        elif na_count < total_categories:  # Some N/A - partial data extracted\n",
    "            score += 0.8\n",
    "        elif na_count == total_categories:  # All N/A - only if truly no data\n",
    "            # This should be rare and only for documents with no extractable data\n",
    "            score += 0.3\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 5. Data extraction quality - check if actual data was extracted when possible\n",
    "    try:\n",
    "        csv_data = pd.read_csv(io.StringIO(pred.out_csv))\n",
    "        last_row = csv_data.iloc[-1]\n",
    "\n",
    "        # Check if meaningful data was extracted (not just filename)\n",
    "        meaningful_data = False\n",
    "        for col in csv_data.columns:\n",
    "            if col != 'document':  # Skip document name column\n",
    "                val = str(last_row[col]).strip()\n",
    "                if val not in ['N/A', '', 'nan'] and len(val) > 1:\n",
    "                    meaningful_data = True\n",
    "                    break\n",
    "\n",
    "        if meaningful_data:\n",
    "            score += 1.0\n",
    "        else:\n",
    "            score += 0.2  # Some credit for proper format even without data\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return score / max_score\n",
    "\n",
    "print(\"Evaluation metric defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "note-about-optimization",
   "metadata": {},
   "source": [
    "## Note about DSPy Example Format\n",
    "\n",
    "The error we encountered earlier was due to improper example formatting. The `with_inputs()` method is crucial for DSPy optimization to work properly. It tells DSPy which fields are inputs vs outputs for the signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approach: Manual prompt optimization\n",
    "# Since BootstrapFewShot requires proper examples, let's try a simpler approach\n",
    "\n",
    "print(\"Setting up manual optimization approach...\")\n",
    "print(\"This approach focuses on improving the signature description and few-shot examples.\")\n",
    "\n",
    "# Create an optimized version of the doc_analyzer signature\n",
    "class optimized_doc_analyzer(dspy.Signature):\n",
    "    \"\"\"Advanced document analyzer that extracts structured information from documents and maintains CSV format.\n",
    "    \n",
    "    Key instructions:\n",
    "    1. Extract data for each category from the document content\n",
    "    2. Use 'N/A' when information is not available or not applicable\n",
    "    3. Maintain proper CSV format with headers and comma separation\n",
    "    4. Keep context updates brief and relevant to avoid token bloat\n",
    "    5. Focus on extracting meaningful data patterns and trends\"\"\"\n",
    "    \n",
    "    document: Attachments = dspy.InputField(\n",
    "        desc=\"Document to analyze - extract information matching the specified categories\")\n",
    "    categories: list[str] = dspy.InputField(\n",
    "        desc=\"List of data categories to extract from the document (e.g., 'violations', 'revenue', etc.)\")\n",
    "    in_csv: str = dspy.InputField(\n",
    "        desc=\"Existing CSV data with headers. Append new row with current document's data\")\n",
    "    last_context: str = dspy.InputField(\n",
    "        desc=\"Previous context and trends identified. Keep this information and add new insights if significant\")\n",
    "    \n",
    "    next_context: str = dspy.OutputField(\n",
    "        desc=\"Updated context with new trends or patterns. Keep brief (under 50 words) to prevent context bloat\")\n",
    "    out_csv: str = dspy.OutputField(\n",
    "        desc=\"CSV with new row added. Format: proper headers, comma-separated values, use 'N/A' for missing data\")\n",
    "\n",
    "print(\"Optimized signature created with enhanced instructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-optimized-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimized module and save it\n",
    "optimized_module = dspy.ChainOfThought(optimized_doc_analyzer)\n",
    "\n",
    "# Test the optimized module with a simple example\n",
    "test_doc = \"Sample inspection report with 2 violations: missing fire extinguisher and blocked exit.\"\n",
    "test_result = optimized_module(\n",
    "    document=test_doc,\n",
    "    categories=[\"document\", \"number of violations\"],\n",
    "    in_csv=\"document,number of violations\",\n",
    "    last_context=\"Testing optimized signature\"\n",
    ")\n",
    "\n",
    "print(\"Test Results:\")\n",
    "print(f\"Context: {test_result.next_context}\")\n",
    "print(f\"CSV Output: {test_result.out_csv}\")\n",
    "\n",
    "# Create directory for optimized modules\n",
    "import os\n",
    "os.makedirs('optimized_modules', exist_ok=True)\n",
    "\n",
    "# Save the optimized module\n",
    "optimized_module.save('optimized_modules/optimized_doc_analyzer.json')\n",
    "print(\"\\nOptimized module saved to 'optimized_modules/optimized_doc_analyzer.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-instructions",
   "metadata": {},
   "source": [
    "## How to Use the Optimized Module\n",
    "\n",
    "The optimized signature has been saved and can be used in your main code. Here are two ways to integrate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usage-examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load and use directly\n",
    "import dspy\n",
    "from modules import doc_analyzer\n",
    "\n",
    "# Create and load optimized module\n",
    "optimized_doc_analyzer_module = dspy.ChainOfThought(optimized_doc_analyzer)\n",
    "# Note: The optimized version uses the enhanced signature defined above\n",
    "\n",
    "# Option 2: Modify your trend_analyzer class\n",
    "class optimized_trend_analyzer(dspy.Module):\n",
    "    def __init__(self, use_optimized=True):\n",
    "        super().__init__()\n",
    "        if use_optimized:\n",
    "            self.doc_analyzer_sql = dspy.ChainOfThought(optimized_doc_analyzer)\n",
    "            print(\"Using optimized doc_analyzer signature\")\n",
    "        else:\n",
    "            from modules import doc_analyzer\n",
    "            self.doc_analyzer_sql = dspy.ChainOfThought(doc_analyzer)\n",
    "            print(\"Using original doc_analyzer signature\")\n",
    "\n",
    "    def forward(self, documents: list[Attachments], categories: list[str], context: str):\n",
    "        # Same implementation as before\n",
    "        doc_summary = \"\"\n",
    "        for document in documents:\n",
    "            result = self.doc_analyzer_sql(\n",
    "                document=document,\n",
    "                categories=categories,\n",
    "                in_csv=doc_summary,\n",
    "                last_context=context\n",
    "            )\n",
    "            context = result.next_context\n",
    "            doc_summary = result.out_csv\n",
    "        return doc_summary, context\n",
    "\n",
    "print(\"Usage examples defined. You can now use optimized_trend_analyzer in your main code.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
